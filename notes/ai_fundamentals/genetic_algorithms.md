---
id: genetic_algorithms
aliases: []
tags:
  - master
  - ai_fundamentals
---

# Genetic Algorithms

A branch of _evolutionary optimization_ that is quite popular is relative to
**genetic algorithms**, that can be seen a general purpose optimization
protocols, initially designed to work on binary representation of data, but that
now can work basically on many more.

They are very useful for problems with several local optima, high-dimensional
and combinatorial problems. They are also used to find solutions for NP-complete
problems. They also are very useful in multi-objective optimization because a
population basically creates a _Parento front_ that can be explored.

The classical setup of a genetic algorithm is a population of individuals
representing candidate solutions. Each of them is represented by a vector of
features called **chromosome**, representing the **genotype**.

The individual **phenotype** can be generated by its genotype; for example in
the knapsack problem we have a binary representation of which object is taken
and which is not. The phenotype is list of taken object with their total value
and total weight.

The other part is given by the classical evolutionary algorithm loop, in which,
for each generation, we select some parents, recombine their chromosomes, mutate
the offsprings and, after evaluate them we keep some based on fitness and some
survival policy.

## Crossover

The operator that make possible to recombine genotypes is the **crossover**,
that can be implemented in various ways and always depends on the problem.

Usually before the crossover there is a **selection** part where parents are
chosen proportionally to their fitness. After that their chromosomes are
combined.

The most used setup is to have many couples of $2$ parents that give birth to
$2$ offsprings with a **$k$-point crossover**, with $k$ typically small ($1$ or
$2$).

This kind of crossover split the chromosome in $k$ points for each parents and
then switching aligned pieces to create offsprings. For example if we have
parents

$$P_1 = 0100 \quad P_2 = 1101$$

with a $1$-point crossover that splits the chromosome in two halves, we obtain

$$P_1 = 01 | 00 \quad P_2 = 11 | 01$$

and so the offsprings will be

$$O_1 = 0101 \quad O_2 = 1100$$

Often the split point is randomly chosen at each generation or for each couple
of parents (anyway must be the same for each couple).

## Mutation

The **mutation** is even more problem-based but usually mutates with a low
probability one (or a few) gene(s) in order to introduce some variability.

An example of mutation for the previous example is to randomly choose a gene and
_flip_ it:

$$O_1 = 0101 \to 0111$$

here we flipped the third bit.

## Encoding

The **input encoding** is crucial in order to have an efficient search; wrong
encodings could also make it impossible to find a solution.

There are two types of encoding:

- **Direct**: each element of the genotype is associated with a feature in the
  phenotype. This means that for each phenotype feature is necessary to have a
  corresponding genotype representation. This is simple but does not scales well
  in more complex and structured problems.
- **Indirect**: the genotype is like a set of rules to build the solution. This
  is more flexible but can be more challenging to design.

When we want to generate **modular phenotypes**, indirect encoding is generally
better in every possible way, while with direct encoding we can solve problems
with a more fixed structure.

One of the main advantages of indirect encoding is the reduction the search
space dimensionality, because one feature of the genotype can now produce
multiple features of the phenotype.

### Compositional Patterns Producing Networks

A technique used in many fields is the so called **compositional patterns
producing networks**, that is a popular way to design **developmental
encodings**.

A developmental encoding is a function that takes phenotypical's space
coordinates and produces phenotypical value as output.

Typically we have a network of functions that produces a pattern of some kind,
like an image. The process makes the network evolve in order to produce images
with some shape or pattern, or for example images that approximates other
images.

![CPPN|300](cppn.png)

For example the genotype encodes the network topology, and the function of each
node. If for example we are trying to produce images we can now just feed the
network with points and get the result pixel value. With direct encoding instead
a genotype is composed by $m \times n$ components (the size of the picture).

So in this case the advantage of indirect encoding that we obtain a function
that can potentially produce images of some kind of arbitrary dimensions (very
flexible and modular). With direct encoding instead we need to evolve again
every feature (pixel) if we change $m$ or $n$.

---

For CPPN the most popular algorithm is **NEAT** that uses a direct encoding (all
nodes and connections are in the genome) to produce networks, that are the
function for the indirect encoding.

The HyperNEAT algorithm is a cycle in which NEAT evolves a CPPN, that is used to
generate a neural network.

## References

- [[evolutionary_optimization]]
